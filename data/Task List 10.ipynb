{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018/2019 - Task List 10\n",
    "\n",
    "1. Implement Naive Bayes classifier with pyro\n",
    "    - create apropriate parameters (mean and std for a and b, sigma - noise)\n",
    "    - provide optimization procedure\n",
    "    - check appropriateness of implemented method with selected dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.optim as optim\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, TracePredictive\n",
    "from pyro.optim import Adam\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('wine.csv', header=None)\n",
    "wine.columns = [\"classname\", \"Alcohol\", \"MalicAcid\", \"Ash\", \"AlcalinityOfAsh\", \"Magnesium\", \"TotalPhenols\",\"Flavanoids\", \n",
    "                \"NonflavanoidPhenols\", \"Proanthocyanins\", \"ColorIntensivity\", \"Hue\",\"OD280/OD315\", \"Proline\"]\n",
    "\n",
    "df = wine\n",
    "# num_columns = df.shape[1]\n",
    "# num_rows = df.shape[0]\n",
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    data = torch.tensor(data.values).float()\n",
    "    num_columns = data.shape[1]\n",
    "    \n",
    "    mean_prior = data[0]\n",
    "    std_prior = torch.ones(num_columns)\n",
    "#     noise_std = torch.ones(num_columns)\n",
    "    \n",
    "    prior = pyro.distributions.Normal(loc=mean_prior, scale=std_prior).independent(1)\n",
    "    weight = pyro.sample(\"weight\", prior)\n",
    "    \n",
    "    with pyro.plate(\"map\", len(data)):\n",
    "        #sample = pyro.sample(\"obs\", pyro.distributions.Normal(weight, noise_std), obs=data)\n",
    "        sample = pyro.sample(\"obs\", prior, obs=data)\n",
    "        return sample\n",
    "\n",
    "\n",
    "def guide(data):\n",
    "    num_columns = data.shape[1]\n",
    "    \n",
    "    mean = pyro.param(\"mean\", torch.ones(1, num_columns)*0)\n",
    "    std = pyro.param(\"std\", torch.ones(1, num_columns)*1, constraint=constraints.positive)\n",
    "    \n",
    "    dists = pyro.distributions.Normal(loc=mean, scale=std).independent(1)\n",
    "    sample = pyro.sample(\"weight\", dists)  # , infer={'is_auxiliary': True}\n",
    "    return sample\n",
    "\n",
    "\n",
    "def train(data, num_steps=5000):\n",
    "    pyro.clear_param_store()\n",
    "    \n",
    "    optim = Adam({\"lr\": 0.01})\n",
    "    svi = pyro.infer.SVI(model=model,\n",
    "                         guide=guide,\n",
    "                         optim=optim,\n",
    "                         loss=pyro.infer.Trace_ELBO(), num_samples=len(data))\n",
    "\n",
    "    losses = []\n",
    "    for t in tqdm(range(num_steps)):\n",
    "        losses.append(svi.step(data))\n",
    "    return pyro.param(\"mean\"), pyro.param(\"std\"), losses\n",
    "\n",
    "\n",
    "def plot_loss(losses, learned_mean, learned_std, print_info=False):\n",
    "    columns_data = [df[i] for i in df.columns]\n",
    "    \n",
    "    true_mean = [np.mean(x) for x in columns_data]\n",
    "    true_std = [np.std(x) for x in columns_data]\n",
    "    if (print_info):\n",
    "        print(df.columns)\n",
    "        print(\"{}\\n{}\".format(true_mean, true_std))\n",
    "        print()\n",
    "\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"evidence lower bound (ELBO)\")\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(\"loss\");\n",
    "    if (print_info):\n",
    "        print('learned mean = ', learned_mean)\n",
    "        print('learned std = ', learned_std)\n",
    "        print()\n",
    "\n",
    "    diff_mean = [learned_mean[i] - true_mean[i] for i in range(len(true_mean))]\n",
    "    diff_std = [learned_std[i] - true_std[i] for i in range(len(true_std))]\n",
    "    if (print_info):\n",
    "        print(diff_mean, \"\\n\", diff_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# _, _, losses = train(data, 20000)\n",
    "\n",
    "# learned_mean = pyro.param(\"mean\").tolist()[0]\n",
    "# learned_std = pyro.param(\"std\").tolist()[0]\n",
    "\n",
    "# plot_loss(losses, learned_mean, learned_std, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(dataset):\n",
    "    # extract labels\n",
    "    dataset_labels = dataset[\"classname\"].copy()\n",
    "    dataset = dataset.drop(\"classname\", axis=1)\n",
    "\n",
    "    return dataset, dataset_labels\n",
    "\n",
    "\n",
    "def preprocess_data(X):\n",
    "    # normalize [0,1]\n",
    "    labels = X[\"classname\"].copy()\n",
    "    X = X.drop(\"classname\", axis=1)\n",
    "    columns = X.columns\n",
    "    \n",
    "    X = pd.DataFrame(normalize(X, axis=0), columns=columns)\n",
    "    X = X.merge(labels, left_index=True, right_index=True)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def split_data(dataset, test_size=0.3):\n",
    "    # split into train and test sets\n",
    "    train_set, test_set = train_test_split(dataset, test_size=test_size, stratify=dataset['classname']) # random_state=42,\n",
    "\n",
    "    # extract labels\n",
    "    train_set_labels = train_set[\"classname\"].copy()\n",
    "    train_set = train_set.drop(\"classname\", axis=1)\n",
    "\n",
    "    test_set_labels = test_set[\"classname\"].copy()\n",
    "    test_set = test_set.drop(\"classname\", axis=1)\n",
    "\n",
    "    return train_set, train_set_labels, test_set, test_set_labels\n",
    "\n",
    "\n",
    "def evaluate(labels_true, labels_predicted):\n",
    "    labels_true = labels_true.values.tolist()\n",
    "    accuracy = metrics.accuracy_score(y_true=labels_true, y_pred=labels_predicted)\n",
    "    precision = metrics.precision_score(y_true=labels_true, y_pred=labels_predicted, average='macro')\n",
    "    recall = metrics.recall_score(y_true=labels_true, y_pred=labels_predicted, average='macro')\n",
    "    f1 = metrics.f1_score(y_true=labels_true, y_pred=labels_predicted, average='macro')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "def test_classifier(train, train_labels, test, test_labels, model):\n",
    "    model.fit(train, train_labels)\n",
    "    labels_predicted = model.predict(test)\n",
    "    labels_true = test_labels\n",
    "    accuracy, precision, recall, f1 = evaluate(labels_true, labels_predicted)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.mean_for_classes = {}\n",
    "        self.std_for_classes = {}\n",
    "        self.classes_probs = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        num_columns = X.shape[1]\n",
    "        self.classes = y.unique()\n",
    "        \n",
    "        for classname in self.classes:\n",
    "            current_data = X[y==classname]\n",
    "            self.classes_probs[classname] = len(current_data)/len(X)\n",
    "            mean, std, _ = train(current_data, num_steps=10000)\n",
    "            self.mean_for_classes[classname] = mean[0]\n",
    "            self.std_for_classes[classname] = std[0]\n",
    "            print(self.classes_probs[classname], self.mean_for_classes[classname], self.std_for_classes[classname])\n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        probs = {}\n",
    "        predicted = []\n",
    "        \n",
    "        for row in X.values:\n",
    "            for classname in self.classes:\n",
    "                p = self.classes_probs[classname]\n",
    "                for i, element in enumerate(row):\n",
    "                    mean = self.mean_for_classes[classname][i].detach().numpy()\n",
    "                    std = self.std_for_classes[classname][i].detach().numpy()\n",
    "                    p *= (1/(np.sqrt(2*np.pi*(std ** 2)))) * (np.e ** (-((element-mean) ** 2)/(2*std ** 2)))\n",
    "                    # print(p)\n",
    "                probs[classname] = p\n",
    "            # print(probs)\n",
    "            chosen_class = max(probs.items(), key=operator.itemgetter(1))[0]\n",
    "            # print(chosen_class)\n",
    "            predicted.append(chosen_class)\n",
    "        \n",
    "        return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(dataset, show=False):\n",
    "    dataset = preprocess_data(dataset)\n",
    "    if (show):\n",
    "        columns_data = [dataset[i] for i in dataset.columns]\n",
    "        true_mean = [np.mean(x) for x in columns_data]\n",
    "        true_std = [np.std(x) for x in columns_data]\n",
    "        print(dataset.columns)\n",
    "        print(\"{}\\n{}\".format(true_mean, true_std))\n",
    "        print()\n",
    "    train_set, train_labels, test_set, test_labels = split_data(dataset)\n",
    "    model = NaiveBayesClassifier()\n",
    "    accuracy, precision, recall, f1 = test_classifier(train_set, train_labels, test_set, test_labels, model)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Alcohol', 'MalicAcid', 'Ash', 'AlcalinityOfAsh', 'Magnesium',\n",
      "       'TotalPhenols', 'Flavanoids', 'NonflavanoidPhenols', 'Proanthocyanins',\n",
      "       'ColorIntensivity', 'Hue', 'OD280/OD315', 'Proline', 'classname'],\n",
      "      dtype='object')\n",
      "[0.07480827469396367, 0.06765587278178141, 0.07445730939417845, 0.0738829589921611, 0.07420052722354029, 0.0723268778565136, 0.0672848416443273, 0.07089929832226441, 0.07055035959065165, 0.068170567305383, 0.0729155184159942, 0.0723421477467212, 0.0690946925050136, 1.9382022471910112]\n",
      "[0.004658279231901258, 0.03225926853208698, 0.008607357658972517, 0.012620851740375043, 0.010595248361343046, 0.019667238433975748, 0.03302616558106141, 0.02431598292276999, 0.025310556882843026, 0.03115688176554472, 0.01735813072357437, 0.019610996595824815, 0.029049974108895607, 0.7728548591122252]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06e0cf6ee4c4d7991d2f3d75e11ad19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33064516129032256 tensor([ 0.0004,  0.0981, -0.0124,  0.0148,  0.1130,  0.0467,  0.0562,  0.0175,\n",
      "         0.1192,  0.0415,  0.0687,  0.1489,  0.1416], grad_fn=<SelectBackward>) tensor([1.0059, 0.9044, 1.1225, 0.8951, 0.9719, 0.9127, 1.0057, 0.9269, 1.0342,\n",
      "        1.0506, 0.9526, 0.9987, 0.9747], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b66cf6374e47d3a7aaaaa0fa4d881d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4032258064516129 tensor([0.1844, 0.1272, 0.0156, 0.0172, 0.1691, 0.0646, 0.0514, 0.0349, 0.1408,\n",
      "        0.0224, 0.0987, 0.0858, 0.0673], grad_fn=<SelectBackward>) tensor([0.9032, 0.9864, 1.0281, 1.0764, 1.0618, 1.0223, 1.0122, 0.9944, 1.0167,\n",
      "        1.0205, 0.9654, 0.9641, 0.8752], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e136b935025418a9e809db97bd54f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2661290322580645 tensor([ 0.0134,  0.1126,  0.0354, -0.0006,  0.0929, -0.0046,  0.0394,  0.1143,\n",
      "        -0.0304,  0.2536,  0.0268,  0.0738,  0.0660], grad_fn=<SelectBackward>) tensor([0.9244, 0.9364, 1.0169, 0.9345, 0.9834, 1.0211, 1.0139, 1.0035, 1.0152,\n",
      "        1.0014, 1.0290, 0.9841, 1.0786], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programowanie\\python\\machine-learning-tests\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "d:\\programowanie\\python\\machine-learning-tests\\venv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3888888888888889, 0.12962962962962962, 0.3333333333333333, 0.18666666666666668)\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(classify(data, show=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

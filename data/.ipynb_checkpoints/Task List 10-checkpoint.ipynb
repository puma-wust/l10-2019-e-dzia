{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2018/2019 - Task List 10\n",
    "\n",
    "1. Implement Naive Bayes classifier with pyro\n",
    "    - create apropriate parameters (mean and std for a and b, sigma - noise)\n",
    "    - provide optimization procedure\n",
    "    - check appropriateness of implemented method with selected dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pyro\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.optim as optim\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal, AutoMultivariateNormal\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, TracePredictive\n",
    "from pyro.optim import Adam\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('wine.csv', header=None)\n",
    "wine.columns = [\"classname\", \"Alcohol\", \"MalicAcid\", \"Ash\", \"AlcalinityOfAsh\", \"Magnesium\", \"TotalPhenols\",\"Flavanoids\", \n",
    "                \"NonflavanoidPhenols\", \"Proanthocyanins\", \"ColorIntensivity\", \"Hue\",\"OD280/OD315\", \"Proline\"]\n",
    "\n",
    "df = wine\n",
    "# num_columns = df.shape[1]\n",
    "# num_rows = df.shape[0]\n",
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    data = torch.tensor(data.values).float()\n",
    "    num_columns = data.shape[1]\n",
    "    \n",
    "    mean_prior = pyro.param(\"mean\", data[0])\n",
    "    std_prior = pyro.param(\"std\", torch.ones(num_columns), constraint=constraints.positive)\n",
    "#     noise_std = torch.ones(num_columns)\n",
    "    \n",
    "    prior = pyro.distributions.Normal(loc=mean_prior, scale=std_prior).independent(1)\n",
    "    weight = pyro.sample(\"weight\", prior)\n",
    "    \n",
    "    with pyro.plate(\"map\", len(data)):\n",
    "        #sample = pyro.sample(\"obs\", pyro.distributions.Normal(weight, noise_std), obs=data)\n",
    "        sample = pyro.sample(\"obs\", prior, obs=data)\n",
    "        return sample\n",
    "\n",
    "\n",
    "def guide(data):\n",
    "    num_columns = data.shape[1]\n",
    "    \n",
    "    mean = pyro.param(\"mean\", torch.ones(1, num_columns)*0)\n",
    "    std = pyro.param(\"std\", torch.ones(1, num_columns)*1, constraint=constraints.positive)\n",
    "    \n",
    "    dists = pyro.distributions.Normal(loc=mean, scale=std).independent(1)\n",
    "    sample = pyro.sample(\"weight\", dists)  # , infer={'is_auxiliary': True})\n",
    "    return sample\n",
    "\n",
    "\n",
    "def train(data, num_steps=5000):\n",
    "    pyro.clear_param_store()\n",
    "    \n",
    "    optim = Adam({\"lr\": 0.01})\n",
    "    svi = pyro.infer.SVI(model=model,\n",
    "                         guide=guide,\n",
    "                         optim=optim,\n",
    "                         loss=pyro.infer.Trace_ELBO(), num_samples=len(data))\n",
    "\n",
    "    losses = []\n",
    "    t = tqdm(range(num_steps))\n",
    "    for j in t:\n",
    "        loss = svi.step(data)\n",
    "        losses.append(loss)\n",
    "        t.set_postfix(loss=loss)\n",
    "    return pyro.param(\"mean\"), pyro.param(\"std\"), losses\n",
    "\n",
    "\n",
    "def plot_loss(losses, learned_mean, learned_std, print_info=False):\n",
    "    columns_data = [df[i] for i in df.columns]\n",
    "    \n",
    "    true_mean = [np.mean(x) for x in columns_data]\n",
    "    true_std = [np.std(x) for x in columns_data]\n",
    "    if (print_info):\n",
    "        print(df.columns)\n",
    "        print(\"{}\\n{}\".format(true_mean, true_std))\n",
    "        print()\n",
    "\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"evidence lower bound (ELBO)\")\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(\"loss\");\n",
    "    if (print_info):\n",
    "        print('learned mean = ', learned_mean)\n",
    "        print('learned std = ', learned_std)\n",
    "        print()\n",
    "\n",
    "    diff_mean = [learned_mean[i] - true_mean[i] for i in range(len(true_mean))]\n",
    "    diff_std = [learned_std[i] - true_std[i] for i in range(len(true_std))]\n",
    "    if (print_info):\n",
    "        print(diff_mean, \"\\n\", diff_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# _, _, losses = train(data, 20000)\n",
    "\n",
    "# learned_mean = pyro.param(\"mean\").tolist()[0]\n",
    "# learned_std = pyro.param(\"std\").tolist()[0]\n",
    "\n",
    "# plot_loss(losses, learned_mean, learned_std, print_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(dataset):\n",
    "    # extract labels\n",
    "    dataset_labels = dataset[\"classname\"].copy()\n",
    "    dataset = dataset.drop(\"classname\", axis=1)\n",
    "\n",
    "    return dataset, dataset_labels\n",
    "\n",
    "\n",
    "def preprocess_data(X):\n",
    "    # normalize [0,1]\n",
    "    labels = X[\"classname\"].copy()\n",
    "    X = X.drop(\"classname\", axis=1)\n",
    "    columns = X.columns\n",
    "    \n",
    "    X = pd.DataFrame(normalize(X, axis=0), columns=columns)\n",
    "    X = X.merge(labels, left_index=True, right_index=True)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def split_data(dataset, test_size=0.3):\n",
    "    # split into train and test sets\n",
    "    train_set, test_set = train_test_split(dataset, test_size=test_size, stratify=dataset['classname']) # random_state=42,\n",
    "\n",
    "    # extract labels\n",
    "    train_set_labels = train_set[\"classname\"].copy()\n",
    "    train_set = train_set.drop(\"classname\", axis=1)\n",
    "\n",
    "    test_set_labels = test_set[\"classname\"].copy()\n",
    "    test_set = test_set.drop(\"classname\", axis=1)\n",
    "\n",
    "    return train_set, train_set_labels, test_set, test_set_labels\n",
    "\n",
    "\n",
    "def evaluate(labels_true, labels_predicted):\n",
    "    # labels_true = labels_true.values.tolist()\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_true=labels_true, y_pred=labels_predicted)\n",
    "    precision = metrics.precision_score(y_true=labels_true, y_pred=labels_predicted, average='macro')\n",
    "    recall = metrics.recall_score(y_true=labels_true, y_pred=labels_predicted, average='macro')\n",
    "    f1 = metrics.f1_score(y_true=labels_true, y_pred=labels_predicted, average='macro')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "def test_classifier(train, train_labels, test, test_labels, model):\n",
    "    model.fit(train, train_labels)\n",
    "    labels_predicted = model.predict(test)\n",
    "    labels_true = test_labels\n",
    "    \n",
    "    temp_labels_t = []\n",
    "    temp_labels_p = []\n",
    "    \n",
    "    for pred, true in zip(labels_predicted, labels_true):\n",
    "        if pred != -1:\n",
    "            temp_labels_t.append(true)\n",
    "            temp_labels_p.append(pred)\n",
    "    \n",
    "    labels_true = temp_labels_t\n",
    "    labels_predicted = temp_labels_p\n",
    "    \n",
    "    n = len(labels_true)\n",
    "    \n",
    "    matrix = confusion_matrix(labels_true, labels_predicted)\n",
    "    accuracy, precision, recall, f1 = evaluate(labels_true, labels_predicted)\n",
    "    return accuracy, precision, recall, f1, matrix, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, confidence_treshold=0.8, num_steps=10000):\n",
    "        self.mean_for_classes = {}\n",
    "        self.std_for_classes = {}\n",
    "        self.classes_probs = {}\n",
    "        self.classes = []\n",
    "        self.confidence_treshold = confidence_treshold\n",
    "        self.num_steps = num_steps\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        num_columns = X.shape[1]\n",
    "        self.classes = y.unique()\n",
    "        \n",
    "        for classname in self.classes:\n",
    "            current_data = X[y==classname]\n",
    "            self.classes_probs[classname] = len(current_data)/len(X)\n",
    "            mean, std, _ = train(current_data, num_steps=self.num_steps)\n",
    "            self.mean_for_classes[classname] = mean[0]\n",
    "            self.std_for_classes[classname] = std[0]\n",
    "            # print(self.classes_probs[classname], self.mean_for_classes[classname], self.std_for_classes[classname])\n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        probs = {}\n",
    "        predicted = []\n",
    "        \n",
    "        for row in X.values:\n",
    "            for classname in self.classes:\n",
    "                p = self.classes_probs[classname]\n",
    "                for i, element in enumerate(row):\n",
    "                    mean = self.mean_for_classes[classname][i].detach().numpy()\n",
    "                    std = self.std_for_classes[classname][i].detach().numpy()\n",
    "                    p *= (1/(np.sqrt(2*np.pi*(std ** 2)))) * (np.e ** (-((element-mean) ** 2)/(2*std ** 2)))\n",
    "                    # print(p)\n",
    "                probs[classname] = p\n",
    "                  \n",
    "            probs = self.sum_to_one(probs)\n",
    "            \n",
    "            chosen_class = max(probs.items(), key=operator.itemgetter(1))[0]\n",
    "            probability = probs[chosen_class]\n",
    "#             print(probability)\n",
    "            if probability >= self.confidence_treshold:\n",
    "                predicted.append(chosen_class)\n",
    "            else:\n",
    "                predicted.append(-1)\n",
    "        \n",
    "        return predicted\n",
    "\n",
    "    def sum_to_one(self, probs):\n",
    "        s = sum(probs.values())\n",
    "        if s == 0:\n",
    "            s = 1\n",
    "        for key in probs.keys():\n",
    "            probs[key] = probs[key]/s\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(dataset, num_steps=10000, confidence_treshold=0.8, show=False):\n",
    "    #dataset = preprocess_data(dataset)\n",
    "    if (show):\n",
    "        columns_data = [dataset[i] for i in dataset.columns]\n",
    "        true_mean = [np.mean(x) for x in columns_data]\n",
    "        true_std = [np.std(x) for x in columns_data]\n",
    "        print(dataset.columns)\n",
    "        print(\"{}\\n{}\".format(true_mean, true_std))\n",
    "        print()\n",
    "    train_set, train_labels, test_set, test_labels = split_data(dataset)\n",
    "    n_done = len(test_set)\n",
    "    model = NaiveBayesClassifier(num_steps=num_steps, confidence_treshold=confidence_treshold)\n",
    "    accuracy, precision, recall, f1, matrix, n_predicted = test_classifier(train_set, train_labels, test_set, test_labels, model)\n",
    "    return accuracy, precision, recall, f1, matrix, n_predicted, n_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d660a5fc50654b1aa43bc4cba0c2046e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1fa2976c1341b9ab7ff64127f08d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d4a62938854976aa219deb53ae7d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 1.0, pr: 1.0, rec: 1.0, f1: 1.0\n",
      "confusion matrix:\n",
      "[[15  0  0]\n",
      " [ 0 19  0]\n",
      " [ 0  0 15]]\n",
      "predicted 49 out of 54\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy, precision, recall, f1, matrix, n_predicted, n_done = classify(data, num_steps=10000, confidence_treshold=0.8, show=False)\n",
    "print(\"acc: {}, pr: {}, rec: {}, f1: {}\\nconfusion matrix:\\n{}\\npredicted {} out of {}\".format(\n",
    "    accuracy, precision, recall, f1, matrix, n_predicted, n_done))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
